{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Machine Learning - Non-Linear Regression Model - Supervised Learning\n",
    "\n",
    "- K Nearest Neighbors\n",
    "\n",
    "- Support Vector \n",
    "\n",
    "- Artificial Neural Network\n",
    "\n",
    "- CART (Classification and Regression)\n",
    "\n",
    "- Random Forest\n",
    "\n",
    "- Gradient Boosting Machines\n",
    "\n",
    "- XGBoost\n",
    "\n",
    "- Light GBM\n",
    "\n",
    "- CatBoost (Categorical Boosting)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## K-Nearest Neighbors Algorithm\n",
    "\n",
    "A supervised machine learning algorithm (as opposed to an unsupervised machine learning algorithm) is one that relies on labeled input data to learn a function that produces an appropriate output when given new unlabeled data.\n",
    "\n",
    "KNN works by finding the distances between a query and all the examples in the data, selecting the specified number examples (K) closest to the query, then votes for the most frequent label (in the case of classification) or averages the labels (in the case of regression).\n",
    "\n",
    "\n",
    "![KNN](./knn.jpeg)\n",
    "\n",
    "**Source:**\n",
    "\n",
    "[Towards Data Science](https://towardsdatascience.com/machine-learning-basics-with-the-k-nearest-neighbors-algorithm-6a6e71d01761#:~:text=KNN%20works%20by%20finding%20the,in%20the%20case%20of%20regression)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, scale\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn import neighbors\n",
    "from sklearn.svm import SVR"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from warnings import filterwarnings\n",
    "filterwarnings(\"ignore\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df = pd.read_csv(\"../dataset/Hitters.csv\")\n",
    "df = df.dropna()\n",
    "# Transforming categorical data to dummy data\n",
    "dms = pd.get_dummies(df[[\"League\", \"Division\", \"NewLeague\"]])\n",
    "y = df[\"Salary\"]\n",
    "X_ = df.drop([\"Salary\", \"League\", \"Division\", \"NewLeague\"], axis= 1).astype(\"float64\")\n",
    "X = pd.concat([X_, dms[[\"League_N\", \"Division_W\", \"NewLeague_N\"]]], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "y,\n",
    "test_size = 0.2,\n",
    "random_state =42)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_train.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     AtBat   Hits  HmRun  Runs   RBI  Walks  Years  CAtBat   CHits  CHmRun  \\\n",
       "226  547.0  137.0    2.0  58.0  47.0   12.0    2.0  1038.0   271.0     3.0   \n",
       "220  299.0   75.0    6.0  38.0  23.0   26.0    3.0   580.0   160.0     8.0   \n",
       "128  584.0  158.0   15.0  70.0  84.0   42.0    5.0  2358.0   636.0    58.0   \n",
       "222  381.0  110.0    9.0  61.0  45.0   32.0    7.0  3015.0   834.0    40.0   \n",
       "81   255.0   70.0    7.0  49.0  35.0   43.0   15.0  6311.0  1661.0   154.0   \n",
       "\n",
       "      CRuns   CRBI  CWalks  PutOuts  Assists  Errors  League_N  Division_W  \\\n",
       "226   129.0   80.0    24.0    261.0    459.0    22.0         0           1   \n",
       "220    71.0   33.0    44.0    212.0      1.0     2.0         1           0   \n",
       "128   265.0  316.0   134.0    331.0     20.0     4.0         1           0   \n",
       "222   451.0  249.0   168.0    228.0      7.0     5.0         1           0   \n",
       "81   1019.0  608.0   820.0     51.0     54.0     8.0         1           0   \n",
       "\n",
       "     NewLeague_N  \n",
       "226            0  \n",
       "220            1  \n",
       "128            1  \n",
       "222            1  \n",
       "81             1  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AtBat</th>\n",
       "      <th>Hits</th>\n",
       "      <th>HmRun</th>\n",
       "      <th>Runs</th>\n",
       "      <th>RBI</th>\n",
       "      <th>Walks</th>\n",
       "      <th>Years</th>\n",
       "      <th>CAtBat</th>\n",
       "      <th>CHits</th>\n",
       "      <th>CHmRun</th>\n",
       "      <th>CRuns</th>\n",
       "      <th>CRBI</th>\n",
       "      <th>CWalks</th>\n",
       "      <th>PutOuts</th>\n",
       "      <th>Assists</th>\n",
       "      <th>Errors</th>\n",
       "      <th>League_N</th>\n",
       "      <th>Division_W</th>\n",
       "      <th>NewLeague_N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>547.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1038.0</td>\n",
       "      <td>271.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>459.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>299.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>580.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>584.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2358.0</td>\n",
       "      <td>636.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>316.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>331.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>381.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3015.0</td>\n",
       "      <td>834.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>451.0</td>\n",
       "      <td>249.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>255.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6311.0</td>\n",
       "      <td>1661.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>608.0</td>\n",
       "      <td>820.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "knn_model = KNeighborsRegressor().fit(X_train, y_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Automatically the model assign k value as 5\n",
    "# We will check the k value optimisation later\n",
    "knn_model.n_neighbors"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "knn_model.metric"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'minkowski'"
      ]
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dir(knn_model)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['__abstractmethods__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_impl',\n",
       " '_check_algorithm_metric',\n",
       " '_check_n_features',\n",
       " '_estimator_type',\n",
       " '_fit',\n",
       " '_fit_X',\n",
       " '_fit_method',\n",
       " '_get_param_names',\n",
       " '_get_tags',\n",
       " '_kneighbors_reduce_func',\n",
       " '_more_tags',\n",
       " '_pairwise',\n",
       " '_repr_html_',\n",
       " '_repr_html_inner',\n",
       " '_repr_mimebundle_',\n",
       " '_tree',\n",
       " '_validate_data',\n",
       " '_y',\n",
       " 'algorithm',\n",
       " 'effective_metric_',\n",
       " 'effective_metric_params_',\n",
       " 'fit',\n",
       " 'get_params',\n",
       " 'kneighbors',\n",
       " 'kneighbors_graph',\n",
       " 'leaf_size',\n",
       " 'metric',\n",
       " 'metric_params',\n",
       " 'n_features_in_',\n",
       " 'n_jobs',\n",
       " 'n_neighbors',\n",
       " 'n_samples_fit_',\n",
       " 'p',\n",
       " 'predict',\n",
       " 'radius',\n",
       " 'score',\n",
       " 'set_params',\n",
       " 'weights']"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "knn_model.predict(X_test)[0:5]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([510.3334, 808.3334, 762.5   , 125.5   , 995.    ])"
      ]
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Prediction\n",
    "y_pred = knn_model.predict(X_test)\n",
    "np.sqrt(mean_squared_error(y_test, y_pred))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "404.7724696402799"
      ]
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Model Tuning\n",
    "RMSE = []\n",
    "\n",
    "for k in range(0,10):\n",
    "    k = k+1\n",
    "    knn_model = KNeighborsRegressor(n_neighbors=k).fit(X_train, y_train)\n",
    "    y_pred = knn_model.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    RMSE.append(rmse)\n",
    "    print(\"k=\", k, \"RMSE:\", rmse, \"\\n\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "k= 1 RMSE: 419.07720589645663 \n",
      "\n",
      "k= 2 RMSE: 378.0502277324553 \n",
      "\n",
      "k= 3 RMSE: 392.2975443521745 \n",
      "\n",
      "k= 4 RMSE: 394.25060391156745 \n",
      "\n",
      "k= 5 RMSE: 404.7724696402799 \n",
      "\n",
      "k= 6 RMSE: 407.0381633460914 \n",
      "\n",
      "k= 7 RMSE: 400.1880716892174 \n",
      "\n",
      "k= 8 RMSE: 394.1365904297106 \n",
      "\n",
      "k= 9 RMSE: 398.66638869213017 \n",
      "\n",
      "k= 10 RMSE: 395.8693412183635 \n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# GridSearchCV\n",
    "knn_params = {\"n_neighbors\": np.arange(1,30,1)}\n",
    "knn = KNeighborsRegressor()\n",
    "knn_cv_model = GridSearchCV(knn, knn_params, cv=10).fit(X_train, y_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "knn_cv_model.best_params_"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'n_neighbors': 3}"
      ]
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Tuned Final Model\n",
    "knn_tuned = KNeighborsRegressor(n_neighbors= knn_cv_model.best_params_[\"n_neighbors\"]).fit(X_train, y_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Prediction\n",
    "y_pred = knn_tuned.predict(X_test)\n",
    "np.sqrt(mean_squared_error(y_test, y_pred))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "392.2975443521745"
      ]
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Support Vector Regression\n",
    "\n",
    "The objective of the support vector machine algorithm is to find a hyperplane in an N-dimensional space(N — the number of features) that distinctly classifies the data points.\n",
    "\n",
    "Hyperplanes are decision boundaries that help classify the data points. Data points falling on either side of the hyperplane can be attributed to different classes. Also, the dimension of the hyperplane depends upon the number of features. If the number of input features is 2, then the hyperplane is just a line. If the number of input features is 3, then the hyperplane becomes a two-dimensional plane. It becomes difficult to imagine when the number of features exceeds 3.\n",
    "\n",
    "Support vectors are data points that are closer to the hyperplane and influence the position and orientation of the hyperplane. Using these support vectors, we maximize the margin of the classifier. Deleting the support vectors will change the position of the hyperplane. These are the points that help us build our SVM.\n",
    "\n",
    "\n",
    "![SVM](./svm_reg.png)\n",
    "\n",
    "**Source:**\n",
    "\n",
    "[Towards Data Science](https://towardsdatascience.com/support-vector-machine-introduction-to-machine-learning-algorithms-934a444fca47)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "source": [
    "# Model and Prediction\n",
    "# We can change the svr kernel and we can try \"rbf\"\n",
    "svr_model = SVR(\"linear\").fit(X_train, y_train)\n",
    "svr_model"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "SVR(kernel='linear')"
      ]
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "source": [
    "svr_model.predict(X_train)[0:5]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([300.20165327, 169.45346536, 519.37057457, 562.50758983,\n",
       "       686.05766456])"
      ]
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "svr_model.predict(X_test)[0:5]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([612.39761763, 556.79707247, 781.07233085, 306.47278181,\n",
       "       498.52104898])"
      ]
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "svr_model.intercept_"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([-43.67922349])"
      ]
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "source": [
    "svr_model.coef_"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ -1.52738022,   8.41603061,  -0.62248071,  -2.91633012,\n",
       "         -1.76348539,   4.05664922,   9.59333169,   0.01942209,\n",
       "         -0.6897988 ,   0.0252315 ,   1.61711037,   0.83482588,\n",
       "         -0.89443894,   0.25664992,   0.21656721,  -1.24359453,\n",
       "          2.77033446, -14.48688936,   0.46266861]])"
      ]
     },
     "metadata": {},
     "execution_count": 55
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "# Test\n",
    "y_pred = svr_model.predict(X_test)\n",
    "np.sqrt(mean_squared_error(y_test, y_pred))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "364.68986308043964"
      ]
     },
     "metadata": {},
     "execution_count": 56
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "source": [
    "# Model Tuning\n",
    "svr_model = SVR(\"linear\")\n",
    "svr_model"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "SVR(kernel='linear')"
      ]
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "source": [
    "# Defining penalty coef\n",
    "svr_params = {\"C\": [0.1, 0.5, 1, 3]}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "source": [
    "svr_cv_model = GridSearchCV(svr_model, svr_params , cv=5, verbose= 2, n_jobs= -1).fit(X_train, y_train)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  20 | elapsed:   12.2s remaining:   10.0s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:   43.4s finished\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "source": [
    "svr_cv_model.best_params_"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'C': 0.1}"
      ]
     },
     "metadata": {},
     "execution_count": 60
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "source": [
    "svr_tuned = SVR(\"linear\", C = 0.1).fit(X_train, y_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "source": [
    "y_pred = svr_tuned.predict(X_test)\n",
    "np.sqrt(mean_squared_error(y_test, y_pred))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "373.0293805913751"
      ]
     },
     "metadata": {},
     "execution_count": 62
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Artificial Neural Network\n",
    "\n",
    "An artificial neural network (ANN) is the piece of a computing system designed to simulate the way the human brain analyzes and processes information. It is the foundation of artificial intelligence (AI) and solves problems that would prove impossible or difficult by human or statistical standards. ANNs have self-learning capabilities that enable them to produce better results as more data becomes available.\n",
    "\n",
    "![ANN](./ann.png)\n",
    "\n",
    "**Source:**\n",
    "\n",
    "[Investopia](https://www.investopedia.com/terms/a/artificial-neural-networks-ann.asp#:~:text=An%20artificial%20neural%20network%20(ANN)%20is%20the%20piece%20of%20a,by%20human%20or%20statistical%20standards.)\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "source": [
    "# Model and Training\n",
    "scaler =StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaler = scaler.transform(X_train)\n",
    "X_test_scaler = scaler.transform(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "source": [
    "mlp_model = MLPRegressor().fit(X_train_scaler, y_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "source": [
    "mlp_model._get_param_names()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['activation',\n",
       " 'alpha',\n",
       " 'batch_size',\n",
       " 'beta_1',\n",
       " 'beta_2',\n",
       " 'early_stopping',\n",
       " 'epsilon',\n",
       " 'hidden_layer_sizes',\n",
       " 'learning_rate',\n",
       " 'learning_rate_init',\n",
       " 'max_fun',\n",
       " 'max_iter',\n",
       " 'momentum',\n",
       " 'n_iter_no_change',\n",
       " 'nesterovs_momentum',\n",
       " 'power_t',\n",
       " 'random_state',\n",
       " 'shuffle',\n",
       " 'solver',\n",
       " 'tol',\n",
       " 'validation_fraction',\n",
       " 'verbose',\n",
       " 'warm_start']"
      ]
     },
     "metadata": {},
     "execution_count": 65
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "source": [
    "y_pred = mlp_model.predict(X_test_scaler)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "source": [
    "np.sqrt(mean_squared_error(y_test, y_pred))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "572.1156055484449"
      ]
     },
     "metadata": {},
     "execution_count": 67
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "source": [
    "# Model Tuning\n",
    "mlp_params = { \"alpha\": [0.1, 0.01, 0.02, 0.001, 0.0001],\n",
    "\"hiddlen_layer_sizes\": [(10,20),(5,5), (100,100)]}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mlp_cv_model = GridSearchCV(mlp_model, mlp_params, cv=5, verbose=2, n_jobs =-1).fit(X_train, y_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mlp_cv_model.best_params_"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mlt_tuned = MLPRegressor(alpha= 0.1, hidden_layer_sizes= (100,100)).fit(X_train_scaler,y_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y_pred = mlt_tuned.predict(X_test_scaler)\n",
    "np.sqrt(mean_squared_error(y_test, y_pred))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "348.50378964899"
      ]
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## CART (Classification andd Regresson Tree)\n",
    "\n",
    "A decision tree is a largely used non-parametric effective machine learning modeling technique for regression and classification problems. To find solutions a decision tree makes a sequential, hierarchical decision about the outcomes variable based on the predictor data.\n",
    "The decision tree builds regression or classification models in the form of a tree structure. It breaks down a dataset into smaller and smaller subsets while at the same time an associated decision tree is incrementally developed. The final result is a decision tree with nodes and leaf nodes.\n",
    "The Understanding Level of Decision Tree algorithm is so easy as compared to the classification algorithm.\n",
    "In the Decision tree algorithm, we solve our problem in a tree regression.\n",
    "\n",
    "- **Each internal node of the tree corresponds to an attribute.**\n",
    "- **Each leaf node corresponds to a Class Label.**\n",
    "\n",
    "In the decision tree for predicting a class label for a record, we start from the root of the tree. We compare the value of the root attribute with the record’s attribute on the basis of comparison. We follow the branch corresponding to that value & jump to the next node. We continue comparing our record’s attribute value with other internal nodes of the tree until we reach a leaf node.\n",
    "\n",
    "![Decision Tree](./decision-tree.png)\n",
    "\n",
    "**Source:**\n",
    "\n",
    "[Medium](https://medium.com/machine-learning-researcher/decision-tree-algorithm-in-machine-learning-248fb7de819e)\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "source": [
    "df = pd.read_csv(\"../dataset/Hitters.csv\")\n",
    "df = df.dropna()\n",
    "# Transforming categorical data to dummy data\n",
    "dms = pd.get_dummies(df[[\"League\", \"Division\", \"NewLeague\"]])\n",
    "y = df[\"Salary\"]\n",
    "X_ = df.drop([\"Salary\", \"League\", \"Division\", \"NewLeague\"], axis= 1).astype(\"float64\")\n",
    "X = pd.concat([X_, dms[[\"League_N\", \"Division_W\", \"NewLeague_N\"]]], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "y,\n",
    "test_size = 0.2,\n",
    "random_state =42)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "source": [
    "# Model & Prediction\n",
    "X_train = pd.DataFrame(X_train[\"Hits\"])\n",
    "X_test = pd.DataFrame(X_test[\"Hits\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "source": [
    "cart_model = DecisionTreeRegressor(max_leaf_nodes=3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "source": [
    "cart_model.fit(X_train,y_train)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_leaf_nodes=3)"
      ]
     },
     "metadata": {},
     "execution_count": 73
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "source": [
    "X_grid = np.arange(min(np.array(X_train)), max(np.array(X_train)), 0.01)\n",
    "X_grid = X_grid.reshape((len(X_grid), 1))\n",
    "\n",
    "plt.scatter(X_train, y_train, color=\"red\")\n",
    "plt.plot(X_grid, cart_model.predict(X_grid), color = \"blue\")\n",
    "\n",
    "plt.title(\"CART Regression Tree\")\n",
    "plt.xlabel(\"Number of Hits\")\n",
    "plt.ylabel(\"Salary\")"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Salary')"
      ]
     },
     "metadata": {},
     "execution_count": 74
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "source": [
    "# One independet value prediction wit Hits\n",
    "y_pred = cart_model.predict(X_test)\n",
    "np.sqrt(mean_squared_error(y_test, y_pred))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "431.29048460063217"
      ]
     },
     "metadata": {},
     "execution_count": 75
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "source": [
    "# Many Independent value\n",
    "df = pd.read_csv(\"../dataset/Hitters.csv\")\n",
    "df = df.dropna()\n",
    "# Transforming categorical data to dummy data\n",
    "dms = pd.get_dummies(df[[\"League\", \"Division\", \"NewLeague\"]])\n",
    "y = df[\"Salary\"]\n",
    "X_ = df.drop([\"Salary\", \"League\", \"Division\", \"NewLeague\"], axis= 1).astype(\"float64\")\n",
    "X = pd.concat([X_, dms[[\"League_N\", \"Division_W\", \"NewLeague_N\"]]], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "y,\n",
    "test_size = 0.2,\n",
    "random_state =42)\n",
    "\n",
    "cart_model_2 = DecisionTreeRegressor(max_leaf_nodes=3).fit(X_train, y_train)\n",
    "y_pred = cart_model_2.predict(X_test)\n",
    "np.sqrt(mean_squared_error(y_test, y_pred))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "412.18941897659465"
      ]
     },
     "metadata": {},
     "execution_count": 76
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Model Tuning\n",
    "?cart_model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "source": [
    "cart_params = {\"max_depth\": [2,3,4,5,10,20], \"min_samples_split\": [2,10,5,30,50,10]}\n",
    "cart_model = DecisionTreeRegressor()\n",
    "cart_cv_model = GridSearchCV(cart_model, cart_params, cv=10).fit(X_train, y_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "source": [
    "cart_cv_model.best_params_"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'max_depth': 5, 'min_samples_split': 50}"
      ]
     },
     "metadata": {},
     "execution_count": 79
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "source": [
    "# Final Model\n",
    "cart_model_tuned = DecisionTreeRegressor(max_depth=5, min_samples_split=50).fit(X_train, y_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "source": [
    "y_pred = cart_cv_model.predict(X_test)\n",
    "np.sqrt(mean_squared_error(y_test, y_pred))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "386.1879001714701"
      ]
     },
     "metadata": {},
     "execution_count": 81
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Random Forest Algorithm\n",
    "\n",
    "Random forest, like its name implies, consists of a large number of individual decision trees that operate as an ensemble. Each individual tree in the random forest spits out a class prediction and the class with the most votes becomes our model’s prediction (see figure below).\n",
    "\n",
    "![Random Forest](./random-forest.jpeg)\n",
    "\n",
    "The fundamental concept behind random forest is a simple but powerful one — the wisdom of crowds. In data science speak, the reason that the random forest model works so well is:\n",
    "\n",
    "- A large number of relatively uncorrelated models (trees) operating as a committee will outperform any of the individual constituent models.\n",
    "\n",
    "The low correlation between models is the key. Just like how investments with low correlations (like stocks and bonds) come together to form a portfolio that is greater than the sum of its parts, uncorrelated models can produce ensemble predictions that are more accurate than any of the individual predictions. The reason for this wonderful effect is that the trees protect each other from their individual errors (as long as they don’t constantly all err in the same direction). While some trees may be wrong, many other trees will be right, so as a group the trees are able to move in the correct direction. So the prerequisites for random forest to perform well are:\n",
    "\n",
    "- There needs to be some actual signal in our features so that models built using those features do better than random guessing.\n",
    "\n",
    "- The predictions (and therefore the errors) made by the individual trees need to have low correlations with each other.\n",
    "\n",
    "\n",
    "**Source:**\n",
    "\n",
    "[Towards Data Science](https://towardsdatascience.com/understanding-random-forest-58381e0602d2)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "source": [
    "# Model & Prediction\n",
    "\n",
    "df = pd.read_csv(\"../dataset/Hitters.csv\")\n",
    "df = df.dropna()\n",
    "# Transforming categorical data to dummy data\n",
    "dms = pd.get_dummies(df[[\"League\", \"Division\", \"NewLeague\"]])\n",
    "y = df[\"Salary\"]\n",
    "X_ = df.drop([\"Salary\", \"League\", \"Division\", \"NewLeague\"], axis= 1).astype(\"float64\")\n",
    "X = pd.concat([X_, dms[[\"League_N\", \"Division_W\", \"NewLeague_N\"]]], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "y,\n",
    "test_size = 0.2,\n",
    "random_state =42)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "source": [
    "rf_model = RandomForestRegressor(random_state=42).fit(X_train, y_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "?rf_model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "source": [
    "y_pred = rf_model.predict(X_test)\n",
    "np.sqrt(mean_squared_error(y_test, y_pred))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "304.96267632952913"
      ]
     },
     "metadata": {},
     "execution_count": 85
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "source": [
    "# Model Tuning\n",
    "\n",
    "rf_params = {\"max_depth\": [5,8,10], \"max_features\": [2,5,10], \"n_estimators\": [200,500, 1000, 2000], \"min_samples_split\": [2,10,80,100]}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "source": [
    "rf_cv_model = GridSearchCV(rf_model, rf_params, cv =10, verbose=2, n_jobs=-1).fit(X_train, y_train)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 10 folds for each of 144 candidates, totalling 1440 fits\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed:   17.9s\n",
      "[Parallel(n_jobs=-1)]: Done 333 tasks      | elapsed:   45.7s\n",
      "[Parallel(n_jobs=-1)]: Done 616 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 981 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1440 out of 1440 | elapsed:  4.4min finished\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "source": [
    "rf_cv_model.best_params_"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'max_depth': 8,\n",
       " 'max_features': 2,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 200}"
      ]
     },
     "metadata": {},
     "execution_count": 90
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "source": [
    "# Final Model\n",
    "rf_model = RandomForestRegressor(random_state=42, max_depth=8, max_features=2, min_samples_split=2, n_estimators=200)\n",
    "rf_tuned = rf_model.fit(X_train, y_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "source": [
    "# Final Model\n",
    "y_pred = rf_tuned.predict(X_test)\n",
    "np.sqrt(mean_squared_error(y_test, y_pred))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "323.2818281763631"
      ]
     },
     "metadata": {},
     "execution_count": 93
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "source": [
    "# Feature Importance\n",
    "importance = pd.DataFrame({\"Importance\": rf_tuned.feature_importances_*100},\n",
    "                            index = X_train.columns)\n",
    "\n",
    "importance.sort_values(by = \"Importance\", axis= 0, ascending=True).plot(kind=\"barh\")\n",
    "plt.xlabel(\"Feature Importance\")\n",
    "plt.gca().legend = None"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Gradient Boosting Machines\n",
    "\n",
    "What is Gradient Boosting?\n",
    "Let’s start by understanding Boosting! Boosting is a method of converting weak learners into strong learners. In boosting, each new tree is a fit on a modified version of the original data set. The gradient boosting algorithm (gbm) can be most easily explained by first introducing the AdaBoost Algorithm.The AdaBoost Algorithm begins by training a decision tree in which each observation is assigned an equal weight. After evaluating the first tree, we increase the weights of those observations that are difficult to classify and lower the weights for those that are easy to classify. The second tree is therefore grown on this weighted data. Here, the idea is to improve upon the predictions of the first tree. Our new model is therefore Tree 1 + Tree 2. We then compute the classification error from this new 2-tree ensemble model and grow a third tree to predict the revised residuals. We repeat this process for a specified number of iterations. Subsequent trees help us to classify observations that are not well classified by the previous trees. Predictions of the final ensemble model is therefore the weighted sum of the predictions made by the previous tree models.\n",
    "\n",
    "Gradient Boosting trains many models in a gradual, additive and sequential manner. The major difference between AdaBoost and Gradient Boosting Algorithm is how the two algorithms identify the shortcomings of weak learners (eg. decision trees). While the AdaBoost model identifies the shortcomings by using high weight data points, gradient boosting performs the same by using gradients in the loss function (y=ax+b+e , e needs a special mention as it is the error term). The loss function is a measure indicating how good are model’s coefficients are at fitting the underlying data. A logical understanding of loss function would depend on what we are trying to optimise. For example, if we are trying to predict the sales prices by using a regression, then the loss function would be based off the error between true and predicted house prices. Similarly, if our goal is to classify credit defaults, then the loss function would be a measure of how good our predictive model is at classifying bad loans. One of the biggest motivations of using gradient boosting is that it allows one to optimise a user specified cost function, instead of a loss function that usually offers less control and does not essentially correspond with real world applications.\n",
    "\n",
    "![Gradient boosting](./gradient-boosting.png)\n",
    "\n",
    "\n",
    "**Source:**\n",
    "\n",
    "[Towards Data Science](https://towardsdatascience.com/understanding-gradient-boosting-machines-9be756fe76ab)\n",
    "\n",
    "[Akira AI](https://www.akira.ai/glossary/gradient-boosting/)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "source": [
    "# Model & Prediction\n",
    "\n",
    "df = pd.read_csv(\"../dataset/Hitters.csv\")\n",
    "df = df.dropna()\n",
    "# Transforming categorical data to dummy data\n",
    "dms = pd.get_dummies(df[[\"League\", \"Division\", \"NewLeague\"]])\n",
    "y = df[\"Salary\"]\n",
    "X_ = df.drop([\"Salary\", \"League\", \"Division\", \"NewLeague\"], axis= 1).astype(\"float64\")\n",
    "X = pd.concat([X_, dms[[\"League_N\", \"Division_W\", \"NewLeague_N\"]]], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "y,\n",
    "test_size = 0.2,\n",
    "random_state =42)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "source": [
    "gbm_model = GradientBoostingRegressor().fit(X_train, y_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "?gbm_model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "source": [
    "y_pred = gbm_model.predict(X_test)\n",
    "np.sqrt(mean_squared_error(y_test, y_pred))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "293.0789707189119"
      ]
     },
     "metadata": {},
     "execution_count": 100
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "source": [
    "# Model Tuning\n",
    "gbm_params = {\"learning_rate\": [0.001,0.1,0.01], \"max_depth\": [3,5,8], \"n_estimators\": [100,200,500], \"subsample\": [1,0.5,0.8], \"loss\": [\"ls\", \"lad\", \"quantile\"] }"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "source": [
    "gbm_cv_model = GridSearchCV(gbm_model, gbm_params, cv=10, verbose=2, n_jobs=-1).fit(X_train, y_train)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 10 folds for each of 243 candidates, totalling 2430 fits\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed:    5.1s\n",
      "[Parallel(n_jobs=-1)]: Done 333 tasks      | elapsed:   12.7s\n",
      "[Parallel(n_jobs=-1)]: Done 616 tasks      | elapsed:   32.7s\n",
      "[Parallel(n_jobs=-1)]: Done 981 tasks      | elapsed:   53.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1426 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1953 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 2430 out of 2430 | elapsed:  2.8min finished\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "source": [
    "gbm_cv_model.best_params_"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'learning_rate': 0.1,\n",
       " 'loss': 'lad',\n",
       " 'max_depth': 5,\n",
       " 'n_estimators': 200,\n",
       " 'subsample': 1}"
      ]
     },
     "metadata": {},
     "execution_count": 103
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "source": [
    "gbm_tuned_model = GradientBoostingRegressor(learning_rate=0.1, loss= \"lad\", max_depth=5, n_estimators=200, subsample=1).fit(X_train, y_train)\n",
    "y_pred = gbm_tuned_model.predict(X_test)\n",
    "np.sqrt(mean_squared_error(y_test, y_pred))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "302.69359180647876"
      ]
     },
     "metadata": {},
     "execution_count": 105
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "source": [
    "# Feature Importance\n",
    "importance = pd.DataFrame({\"Importance\": gbm_tuned_model.feature_importances_*100},\n",
    "                            index = X_train.columns)\n",
    "\n",
    "importance.sort_values(by = \"Importance\", axis= 0, ascending=True).plot(kind=\"barh\", color = \"orange\")\n",
    "plt.xlabel(\"Feature Importance\")\n",
    "plt.gca().legend = None"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# XGBoost Algorithm\n",
    "\n",
    "XGBoost is a decision-tree-based ensemble Machine Learning algorithm that uses a gradient boosting framework. In prediction problems involving unstructured data (images, text, etc.) artificial neural networks tend to outperform all other algorithms or frameworks. However, when it comes to small-to-medium structured/tabular data, decision tree based algorithms are considered best-in-class right now. \n",
    "\n",
    "![XGBoost](./xgboost.jpeg)\n",
    "\n",
    "The algorithm differentiates itself in the following ways:\n",
    "\n",
    "- A wide range of applications: Can be used to solve regression, classification, ranking, and user-defined prediction problems.\n",
    "\n",
    "- Portability: Runs smoothly on Windows, Linux, and OS X.\n",
    "\n",
    "- Languages: Supports all major programming languages including C++, Python, R, Java, Scala, and Julia.\n",
    "\n",
    "- Cloud Integration: Supports AWS, Azure, and Yarn clusters and works well with Flink, Spark, and other ecosystems.\n",
    "\n",
    "Each step of the evolution of tree-based algorithms can be viewed as below.\n",
    "\n",
    "- **Decision Tree:** Every hiring manager has a set of criteria such as education level, number of years of experience, interview performance. A decision tree is analogous to a hiring manager interviewing candidates based on his or her own criteria.\n",
    "\n",
    "- **Bagging:** Now imagine instead of a single interviewer, now there is an interview panel where each interviewer has a vote. Bagging or bootstrap aggregating involves combining inputs from all interviewers for the final decision through a democratic voting process.\n",
    "\n",
    "- **Random Forest:** It is a bagging-based algorithm with a key difference wherein only a subset of features is selected at random. In other words, every interviewer will only test the interviewee on certain randomly selected qualifications (e.g. a technical interview for testing programming skills and a behavioral interview for evaluating non-technical skills).\n",
    "\n",
    "- **Boosting:** This is an alternative approach where each interviewer alters the evaluation criteria based on feedback from the previous interviewer. This ‘boosts’ the efficiency of the interview process by deploying a more dynamic evaluation process.\n",
    "\n",
    "- **Gradient Boosting:** A special case of boosting where errors are minimized by gradient descent algorithm e.g. the strategy consulting firms leverage by using case interviews to weed out less qualified candidates.\n",
    "\n",
    "- **XGBoost:** Think of XGBoost as gradient boosting on ‘steroids’ (well it is called ‘Extreme Gradient Boosting’ for a reason!). It is a perfect combination of software and hardware optimization techniques to yield superior results using less computing resources in the shortest amount of time.\n",
    "\n",
    "**Why does XGBoost perform so well?**\n",
    "\n",
    "**System Optimization:**\n",
    "\n",
    "\n",
    "- **Parallelization:** XGBoost approaches the process of sequential tree building using parallelized implementation. This is possible due to the interchangeable nature of loops used for building base learners; the outer loop that enumerates the leaf nodes of a tree, and the second inner loop that calculates the features. This nesting of loops limits parallelization because without completing the inner loop (more computationally demanding of the two), the outer loop cannot be started. Therefore, to improve run time, the order of loops is interchanged using initialization through a global scan of all instances and sorting using parallel threads. This switch improves algorithmic performance by offsetting any parallelization overheads in computation.\n",
    "\n",
    "\n",
    "- **Tree Pruning:** The stopping criterion for tree splitting within GBM framework is greedy in nature and depends on the negative loss criterion at the point of split. XGBoost uses ‘max_depth’ parameter as specified instead of criterion first, and starts pruning trees backward. This ‘depth-first’ approach improves computational performance significantly.\n",
    "\n",
    "- **Hardware Optimization:** This algorithm has been designed to make efficient use of hardware resources. This is accomplished by cache awareness by allocating internal buffers in each thread to store gradient statistics. Further enhancements such as ‘out-of-core’ computing optimize available disk space while handling big data-frames that do not fit into memory.\n",
    "\n",
    "**Algorithmic Enhancements:**\n",
    "\n",
    "- **Regularization:** It penalizes more complex models through both LASSO (L1) and Ridge (L2) regularization to prevent overfitting.\n",
    "\n",
    "- Sparsity Awareness:** XGBoost naturally admits sparse features for inputs by automatically ‘learning’ best missing value depending on training loss and handles different types of sparsity patterns in the data more efficiently.\n",
    "\n",
    "- **Weighted Quantile Sketch:** XGBoost employs the distributed weighted Quantile Sketch algorithm to effectively find the optimal split points among weighted datasets.\n",
    "\n",
    "- **Cross-validation:** The algorithm comes with built-in cross-validation method at each iteration, taking away the need to explicitly program this search and to specify the exact number of boosting iterations required in a single run.\n",
    "\n",
    "![XGBoost_2](./xgboost2.png)\n",
    "\n",
    "\n",
    "**Source:**\n",
    "\n",
    "[Towards Data Science](https://towardsdatascience.com/https-medium-com-vishalmorde-xgboost-algorithm-long-she-may-rein-edd9f99be63d#:~:text=XGBoost%20is%20a%20decision%2Dtree,all%20other%20algorithms%20or%20frameworks.)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Model & Prediction\n",
    "\n",
    "df = pd.read_csv(\"../dataset/Hitters.csv\")\n",
    "df = df.dropna()\n",
    "# Transforming categorical data to dummy data\n",
    "dms = pd.get_dummies(df[[\"League\", \"Division\", \"NewLeague\"]])\n",
    "y = df[\"Salary\"]\n",
    "X_ = df.drop([\"Salary\", \"League\", \"Division\", \"NewLeague\"], axis= 1).astype(\"float64\")\n",
    "X = pd.concat([X_, dms[[\"League_N\", \"Division_W\", \"NewLeague_N\"]]], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "y,\n",
    "test_size = 0.2,\n",
    "random_state =42)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "source": [
    "!pip install xgboost"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-1.4.2-py3-none-macosx_10_14_x86_64.macosx_10_15_x86_64.macosx_11_0_x86_64.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 285 kB/s \n",
      "\u001b[?25hRequirement already satisfied: scipy in /Users/seneralkan/opt/anaconda3/lib/python3.8/site-packages (from xgboost) (1.5.2)\n",
      "Requirement already satisfied: numpy in /Users/seneralkan/opt/anaconda3/lib/python3.8/site-packages (from xgboost) (1.19.2)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.4.2\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "import xgboost\n",
    "from xgboost import XGBRegressor"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "xgb = XGBRegressor().fit(X_train, y_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "y_pred = xgb.predict(X_test)\n",
    "np.sqrt(mean_squared_error(y_test, y_pred))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "298.061591603747"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "xgb"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=100, n_jobs=16, num_parallel_tree=1, random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "xgb_params = {\"learning_rate\": [0.1,0.01,0.5],\n",
    "\"max_depth\": [2,3,4,5,8],\n",
    "\"n_estimators\": [100,200,500,1000],\n",
    "\"colsample_bytree\": [0.4,0.7,1]}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "xgb_cv_model = GridSearchCV(xgb, xgb_params, verbose=2, cv=10, n_jobs=-1).fit(X_train, y_train)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 10 folds for each of 180 candidates, totalling 1800 fits\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 333 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=-1)]: Done 616 tasks      | elapsed:  8.5min\n",
      "[Parallel(n_jobs=-1)]: Done 981 tasks      | elapsed: 14.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1426 tasks      | elapsed: 21.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1800 out of 1800 | elapsed: 27.2min finished\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "xgb_cv_model.best_params_"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.4,\n",
       " 'learning_rate': 0.01,\n",
       " 'max_depth': 2,\n",
       " 'n_estimators': 1000}"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Light GBM\n",
    "\n",
    "Light GBM is a gradient boosting framework that uses tree based learning algorithm.\n",
    "\n",
    "**How it differs from other tree based algorithm?**\n",
    "\n",
    "Light GBM grows tree vertically while other algorithm grows trees horizontally meaning that Light GBM grows tree leaf-wise while other algorithm grows level-wise. It will choose the leaf with max delta loss to grow. When growing the same leaf, Leaf-wise algorithm can reduce more loss than a level-wise algorithm.\n",
    "\n",
    "Below diagrams explain the implementation of LightGBM and other boosting algorithms.\n",
    "\n",
    "Light GBM\n",
    "\n",
    "![Light GBM](./light-gbm.png)\n",
    "\n",
    "Other Boosting Algorithms\n",
    "\n",
    "![Light GBM Comparison](./light-gbm-comparison.png)\n",
    "\n",
    "The size of data is increasing day by day and it is becoming difficult for traditional data science algorithms to give faster results. Light GBM is prefixed as ‘Light’ because of its high speed. Light GBM can handle the large size of data and takes lower memory to run. Another reason of why Light GBM is popular is because it focuses on accuracy of results. LGBM also supports GPU learning and thus data scientists are widely using LGBM for data science application development.\n",
    "\n",
    "\n",
    "**Can we use Light GBM everywhere?**\n",
    "\n",
    "No, it is not advisable to use LGBM on small datasets. Light GBM is sensitive to overfitting and can easily overfit small data. Their is no threshold on the number of rows but my experience suggests me to use it only for data with 10,000+ rows\n",
    "\n",
    "**Source:**\n",
    "\n",
    "[Light GBM Documentation](https://lightgbm.readthedocs.io/en/latest/Installation-Guide.html#macos)\n",
    "\n",
    "[Medium](https://medium.com/@pushkarmandot/https-medium-com-pushkarmandot-what-is-lightgbm-how-to-implement-it-how-to-fine-tune-the-parameters-60347819b7fc)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# Model & Prediction\n",
    "\n",
    "df = pd.read_csv(\"../dataset/Hitters.csv\")\n",
    "df = df.dropna()\n",
    "# Transforming categorical data to dummy data\n",
    "dms = pd.get_dummies(df[[\"League\", \"Division\", \"NewLeague\"]])\n",
    "y = df[\"Salary\"]\n",
    "X_ = df.drop([\"Salary\", \"League\", \"Division\", \"NewLeague\"], axis= 1).astype(\"float64\")\n",
    "X = pd.concat([X_, dms[[\"League_N\", \"Division_W\", \"NewLeague_N\"]]], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "y,\n",
    "test_size = 0.2,\n",
    "random_state =42)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!pip install lightgbm"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "from lightgbm import LGBMRegressor"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "lgb = LGBMRegressor().fit(X_train, y_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "lgb.get_params"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<bound method LGBMModel.get_params of LGBMRegressor()>"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "y_pred = lgb.predict(X_test)\n",
    "np.sqrt(mean_squared_error(y_test, y_pred))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "353.89197703728786"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "lgb_params = {\"learning_rate\": [0.1, 0.01, 0.5, 1],\n",
    "\"n_estimators\": [100,200,500],\n",
    "\"max_depth\": [2,3,5,10]}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "lgb_cv_model = GridSearchCV(lgb, lgb_params, cv=10, verbose=2, n_jobs= -1).fit(X_train, y_train)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 10 folds for each of 48 candidates, totalling 480 fits\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=-1)]: Done 480 out of 480 | elapsed:    5.8s finished\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "lgb_cv_model.best_params_"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 500}"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "lgbm_tuned_model = LGBMRegressor(learning_rate=0.01, max_depth=5, n_estimators=500).fit(X_train, y_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "y_pred = lgbm_tuned_model.predict(X_test)\n",
    "np.sqrt(mean_squared_error(y_test, y_pred))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "361.7822472211918"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## CatBoost Algorithm\n",
    "\n",
    "The term CatBoost is an acronym that stands for \"Category” and “Boosting.” Does this mean the “Category’ in CatBoost means it only works for categorical features?\n",
    "\n",
    "The answer is, “No.”\n",
    "\n",
    "According to the CatBoost documentation, CatBoost supports numerical, categorical, and text features but has a good handling technique for categorical data. \n",
    "\n",
    "The CatBoost algorithm has quite a number of parameters to tune the features in the processing stage.\n",
    "\n",
    "\"Boosting\" in CatBoost refers to the gradient boosting machine learning. Gradient boosting is a machine learning technique for regression and classification problems. \n",
    "\n",
    "Which produces a prediction model in an ensemble of weak prediction models, typically decision trees. \n",
    "\n",
    "Gradient boosting is a robust machine learning algorithm that performs well when used to provide solutions to different types of business problems such as\n",
    "\n",
    "- Fraud detection, \n",
    "- Recommendation system, \n",
    "- Forecasting\n",
    "\n",
    "Again, it can return an outstanding result with relatively fewer data. Unlike other machine learning algorithms that only perform well after learning from extensive data.\n",
    "\n",
    "\n",
    "**Source:**\n",
    "\n",
    "[Data Aspirant](https://dataaspirant.com/catboost-algorithm/)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "# Model & Prediction\n",
    "\n",
    "df = pd.read_csv(\"../dataset/Hitters.csv\")\n",
    "df = df.dropna()\n",
    "# Transforming categorical data to dummy data\n",
    "dms = pd.get_dummies(df[[\"League\", \"Division\", \"NewLeague\"]])\n",
    "y = df[\"Salary\"]\n",
    "X_ = df.drop([\"Salary\", \"League\", \"Division\", \"NewLeague\"], axis= 1).astype(\"float64\")\n",
    "X = pd.concat([X_, dms[[\"League_N\", \"Division_W\", \"NewLeague_N\"]]], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "y,\n",
    "test_size = 0.2,\n",
    "random_state =42)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "!pip install catboost"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting catboost\n",
      "  Using cached catboost-0.26-cp38-none-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (13.1 MB)\n",
      "Requirement already satisfied: six in /Users/seneralkan/opt/anaconda3/lib/python3.8/site-packages (from catboost) (1.15.0)\n",
      "Collecting plotly\n",
      "  Downloading plotly-5.1.0-py2.py3-none-any.whl (20.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 20.6 MB 6.5 MB/s \n",
      "\u001b[?25hRequirement already satisfied: scipy in /Users/seneralkan/opt/anaconda3/lib/python3.8/site-packages (from catboost) (1.5.2)\n",
      "Collecting graphviz\n",
      "  Downloading graphviz-0.17-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: pandas>=0.24.0 in /Users/seneralkan/opt/anaconda3/lib/python3.8/site-packages (from catboost) (1.1.3)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /Users/seneralkan/opt/anaconda3/lib/python3.8/site-packages (from catboost) (1.19.2)\n",
      "Requirement already satisfied: matplotlib in /Users/seneralkan/opt/anaconda3/lib/python3.8/site-packages (from catboost) (3.3.2)\n",
      "Collecting tenacity>=6.2.0\n",
      "  Downloading tenacity-8.0.1-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: pytz>=2017.2 in /Users/seneralkan/opt/anaconda3/lib/python3.8/site-packages (from pandas>=0.24.0->catboost) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/seneralkan/opt/anaconda3/lib/python3.8/site-packages (from pandas>=0.24.0->catboost) (2.8.1)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in /Users/seneralkan/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->catboost) (2020.6.20)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/seneralkan/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->catboost) (0.10.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/seneralkan/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->catboost) (8.0.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /Users/seneralkan/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->catboost) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/seneralkan/opt/anaconda3/lib/python3.8/site-packages (from matplotlib->catboost) (1.3.0)\n",
      "Installing collected packages: tenacity, plotly, graphviz, catboost\n",
      "Successfully installed catboost-0.26 graphviz-0.17 plotly-5.1.0 tenacity-8.0.1\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "from catboost import CatBoostRegressor"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "catboost = CatBoostRegressor().fit(X_train, y_train)\n",
    "y_pred = catboost.predict(X_test)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "np.sqrt(mean_squared_error(y_test, y_pred))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "311.6017907600214"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "catb_params = {\"iterations\": [200,500,100],\n",
    "\"learning_rate\": [0.01,0,1],\n",
    "\"depth\": [3,6,8]}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "catboost_model = CatBoostRegressor()\n",
    "catb_cv_model = GridSearchCV(catboost_model, catb_params, verbose=2, n_jobs=-1).fit(X_train, y_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "catb_cv_model.best_params_"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'depth': 3, 'iterations': 500, 'learning_rate': 0.01}"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Model Tuning\n",
    "catb_tuned_model = CatBoostRegressor(depth=3, iterations=500, learning_rate=0.01).fit(X_train,y_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "y_pred = catb_tuned_model.predict(X_test)\n",
    "np.sqrt(mean_squared_error(y_test, y_pred))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "333.4330573121869"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Machine Learnig Algorithms - Automatisation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "# Model & Prediction\n",
    "\n",
    "df = pd.read_csv(\"../dataset/Hitters.csv\")\n",
    "df = df.dropna()\n",
    "# Transforming categorical data to dummy data\n",
    "dms = pd.get_dummies(df[[\"League\", \"Division\", \"NewLeague\"]])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "def compML (df, y, alg):\n",
    "    # Train-test split\n",
    "    y = df[y]\n",
    "    X_ = df.drop([\"Salary\", \"League\", \"Division\", \"NewLeague\"], axis= 1).astype(\"float64\")\n",
    "    X = pd.concat([X_, dms[[\"League_N\", \"Division_W\", \"NewLeague_N\"]]], axis=1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2,random_state =42)\n",
    "\n",
    "    # Modelling\n",
    "    model = alg().fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    model_name = alg.__name__\n",
    "    print(model_name, \"Test Error:\", rmse)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "compML(df, \"Salary\", SVR)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "SVR Test Error: 423.8700404711011\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [
    "models = [LGBMRegressor,\n",
    "        XGBRegressor,\n",
    "        GradientBoostingRegressor,\n",
    "        DecisionTreeRegressor,\n",
    "        RandomForestRegressor,\n",
    "        MLPRegressor,\n",
    "        KNeighborsRegressor,\n",
    "        SVR]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "source": [
    "for i in models:\n",
    "    compML(df,\"Salary\", i)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "LGBMRegressor Test Error: 353.89197703728786\n",
      "XGBRegressor Test Error: 298.061591603747\n",
      "GradientBoostingRegressor Test Error: 292.3936848637636\n",
      "DecisionTreeRegressor Test Error: 511.45007765807685\n",
      "RandomForestRegressor Test Error: 296.54312371793776\n",
      "MLPRegressor Test Error: 360.32706245641475\n",
      "KNeighborsRegressor Test Error: 404.7724696402799\n",
      "SVR Test Error: 423.8700404711011\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/seneralkan/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "1a761c32d4b8a6f2a02e99be72b6073eda52173176e7c1f6d5695f36dba36687"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}